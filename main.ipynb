{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STGCN-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from load_data import *\n",
    "from utils import *\n",
    "from stgcn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2333)\n",
    "torch.cuda.manual_seed(2333)\n",
    "np.random.seed(2333)\n",
    "random.seed(2333)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = \"dataset/W_228.csv\"\n",
    "data_path = \"dataset/V_228.csv\"\n",
    "save_path = \"save/model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_slot = 288\n",
    "n_train, n_val, n_test = 34, 5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_his = 12\n",
    "n_pred = 3\n",
    "n_route = 228\n",
    "Ks, Kt = 3, 3\n",
    "blocks = [[1, 32, 64], [64, 32, 128]]\n",
    "drop_prob = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 100\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = load_matrix(matrix_path)\n",
    "L = scaled_laplacian(W)\n",
    "Lk = cheb_poly(L, Ks)\n",
    "Lk = torch.Tensor(Lk.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = load_data(data_path, n_train * day_slot, n_val * day_slot)\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "val = scaler.transform(val)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data_transform(train, n_his, n_pred, day_slot, device)\n",
    "x_val, y_val = data_transform(val, n_his, n_pred, day_slot, device)\n",
    "x_test, y_test = data_transform(test, n_his, n_pred, day_slot, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "val_data = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_iter = torch.utils.data.DataLoader(val_data, batch_size)\n",
    "test_data = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "model = STGCN(Ks, Kt, blocks, n_his, n_route, Lk, drop_prob).to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 , train loss: 0.8044341134795973 , validation loss: 1.2038828292249764\n",
      "epoch 2 , train loss: 0.24997524145195646 , validation loss: 1.185785157293299\n",
      "epoch 3 , train loss: 0.19976207524051784 , validation loss: 1.307962594893727\n",
      "epoch 4 , train loss: 0.18759137688915634 , validation loss: 0.8363337156220074\n",
      "epoch 5 , train loss: 0.18641484175925094 , validation loss: 0.8408583073067839\n",
      "epoch 6 , train loss: 0.1658178586664759 , validation loss: 0.7672417469485833\n",
      "epoch 7 , train loss: 0.16410174378193515 , validation loss: 0.5414866112226987\n",
      "epoch 8 , train loss: 0.16099981485376955 , validation loss: 0.5835458278982308\n",
      "epoch 9 , train loss: 0.16011387618404951 , validation loss: 0.6428865088816107\n",
      "epoch 10 , train loss: 0.15809489180885347 , validation loss: 0.5132702796509231\n",
      "epoch 11 , train loss: 0.1525052316733162 , validation loss: 0.4068056018683162\n",
      "epoch 12 , train loss: 0.1489149090582437 , validation loss: 0.36522067406207975\n",
      "epoch 13 , train loss: 0.14770146008915225 , validation loss: 0.36745671830038085\n",
      "epoch 14 , train loss: 0.14727952288117416 , validation loss: 0.30136161871308825\n",
      "epoch 15 , train loss: 0.14522401718186842 , validation loss: 0.3077472175614242\n",
      "epoch 16 , train loss: 0.14198940878789176 , validation loss: 0.35324521305678536\n",
      "epoch 17 , train loss: 0.1406794466244632 , validation loss: 0.2906890312196129\n",
      "epoch 18 , train loss: 0.14015473822230123 , validation loss: 0.2673102509040032\n",
      "epoch 19 , train loss: 0.1391937364966074 , validation loss: 0.24966009640998213\n",
      "epoch 20 , train loss: 0.1385647309932037 , validation loss: 0.2717068007446989\n",
      "epoch 21 , train loss: 0.1361345035428267 , validation loss: 0.21557165407677636\n",
      "epoch 22 , train loss: 0.13581248369114293 , validation loss: 0.22344202300819166\n",
      "epoch 23 , train loss: 0.1351970233048759 , validation loss: 0.19721849148508405\n",
      "epoch 24 , train loss: 0.1348727852147682 , validation loss: 0.2011425818187477\n",
      "epoch 25 , train loss: 0.1340864064670162 , validation loss: 0.19698455856338035\n",
      "epoch 26 , train loss: 0.1328136620298508 , validation loss: 0.17153720950612622\n",
      "epoch 27 , train loss: 0.1324466812144845 , validation loss: 0.170702886883251\n",
      "epoch 28 , train loss: 0.13192762570602026 , validation loss: 0.16714061122306073\n",
      "epoch 29 , train loss: 0.13174686904160082 , validation loss: 0.16101633095230064\n",
      "epoch 30 , train loss: 0.13124864804848368 , validation loss: 0.15384160687834242\n",
      "epoch 31 , train loss: 0.1302158879064193 , validation loss: 0.15005883381423288\n",
      "epoch 32 , train loss: 0.13001924048279068 , validation loss: 0.16338575621862916\n",
      "epoch 33 , train loss: 0.12984884372752795 , validation loss: 0.14977447227676854\n",
      "epoch 34 , train loss: 0.12946466996805153 , validation loss: 0.1501969840975791\n",
      "epoch 35 , train loss: 0.12926631326478866 , validation loss: 0.1468402404936343\n",
      "epoch 36 , train loss: 0.12870744184401733 , validation loss: 0.1557931790712976\n",
      "epoch 37 , train loss: 0.12856916226718548 , validation loss: 0.1563543114321728\n",
      "epoch 38 , train loss: 0.12837707872245382 , validation loss: 0.14700117803783747\n",
      "epoch 39 , train loss: 0.12825489824117126 , validation loss: 0.14310758771633145\n",
      "epoch 40 , train loss: 0.1280179758835704 , validation loss: 0.14525634828057601\n",
      "epoch 41 , train loss: 0.12755628904754024 , validation loss: 0.14301788907525312\n",
      "epoch 42 , train loss: 0.12753092528138105 , validation loss: 0.14842669637261952\n",
      "epoch 43 , train loss: 0.1273801691347102 , validation loss: 0.14177879890984427\n",
      "epoch 44 , train loss: 0.12725235190851947 , validation loss: 0.14778986642558645\n",
      "epoch 45 , train loss: 0.12715184466714202 , validation loss: 0.14344225456788592\n",
      "epoch 46 , train loss: 0.1268645344792312 , validation loss: 0.14180321801100335\n",
      "epoch 47 , train loss: 0.126698843005544 , validation loss: 0.14155188571308217\n",
      "epoch 48 , train loss: 0.12670617621470387 , validation loss: 0.14225451184613427\n",
      "epoch 49 , train loss: 0.1266027557403297 , validation loss: 0.14186461895269198\n",
      "epoch 50 , train loss: 0.12657624102581874 , validation loss: 0.14198127495002572\n",
      "epoch 51 , train loss: 0.12635488302225767 , validation loss: 0.1426043874128674\n",
      "epoch 52 , train loss: 0.1263684831901956 , validation loss: 0.14172176214574028\n",
      "epoch 53 , train loss: 0.1262449993275685 , validation loss: 0.1412680542545162\n",
      "epoch 54 , train loss: 0.12623028262022895 , validation loss: 0.14138158168779671\n",
      "epoch 55 , train loss: 0.12615324109440815 , validation loss: 0.14340855449057408\n",
      "epoch 56 , train loss: 0.1260361631203742 , validation loss: 0.14112540194424836\n",
      "epoch 57 , train loss: 0.1259791973743151 , validation loss: 0.14162880394363056\n",
      "epoch 58 , train loss: 0.12592594401999674 , validation loss: 0.14127366605085612\n",
      "epoch 59 , train loss: 0.12591507484814085 , validation loss: 0.14094218532860714\n",
      "epoch 60 , train loss: 0.1258807752558145 , validation loss: 0.14196977457099588\n",
      "epoch 61 , train loss: 0.125834310437705 , validation loss: 0.14073750455557865\n",
      "epoch 62 , train loss: 0.12573350155818047 , validation loss: 0.14082124097830187\n",
      "epoch 63 , train loss: 0.12572884699589656 , validation loss: 0.14079009170514822\n",
      "epoch 64 , train loss: 0.12568412077508806 , validation loss: 0.14105726312166147\n",
      "epoch 65 , train loss: 0.12561781264716793 , validation loss: 0.14096273751045665\n",
      "epoch 66 , train loss: 0.1256458685857741 , validation loss: 0.14068181937845953\n",
      "epoch 67 , train loss: 0.12563661646982435 , validation loss: 0.14099847159627146\n",
      "epoch 68 , train loss: 0.12559076639019456 , validation loss: 0.14093558261864378\n",
      "epoch 69 , train loss: 0.1255755020635816 , validation loss: 0.14079034622133213\n",
      "epoch 70 , train loss: 0.12550815206681673 , validation loss: 0.14066415984373892\n",
      "epoch 71 , train loss: 0.1254902359461288 , validation loss: 0.14072447486330558\n",
      "epoch 72 , train loss: 0.12550430376036273 , validation loss: 0.14073636899464323\n",
      "epoch 73 , train loss: 0.12551576404413628 , validation loss: 0.14074023371140887\n",
      "epoch 74 , train loss: 0.12542515705204052 , validation loss: 0.14099604310127942\n",
      "epoch 75 , train loss: 0.1254629970617359 , validation loss: 0.14086721335830044\n",
      "epoch 76 , train loss: 0.12542269380180146 , validation loss: 0.14077474635067214\n",
      "epoch 77 , train loss: 0.12544500613293202 , validation loss: 0.14092022593874132\n",
      "epoch 78 , train loss: 0.1254184662547169 , validation loss: 0.1406769436124685\n",
      "epoch 79 , train loss: 0.12537332149298472 , validation loss: 0.1409293423631113\n",
      "epoch 80 , train loss: 0.1253858858350778 , validation loss: 0.14065384231235858\n",
      "epoch 81 , train loss: 0.1253667797936473 , validation loss: 0.1407033453158436\n",
      "epoch 82 , train loss: 0.12533605663516123 , validation loss: 0.14080555682634785\n",
      "epoch 83 , train loss: 0.1253541690733695 , validation loss: 0.14071977013436548\n",
      "epoch 84 , train loss: 0.1253019952870659 , validation loss: 0.1407312026832008\n",
      "epoch 85 , train loss: 0.12537550927967972 , validation loss: 0.1405732697351788\n",
      "epoch 86 , train loss: 0.1253249067709189 , validation loss: 0.14061538635814277\n",
      "epoch 87 , train loss: 0.1252613776039929 , validation loss: 0.14068982150595988\n",
      "epoch 88 , train loss: 0.12538663435930497 , validation loss: 0.1406923279601292\n",
      "epoch 89 , train loss: 0.1253628087829448 , validation loss: 0.14069615217455983\n",
      "epoch 90 , train loss: 0.125275711918041 , validation loss: 0.14061394722683587\n",
      "epoch 91 , train loss: 0.12525224996936224 , validation loss: 0.14061255027016584\n",
      "epoch 92 , train loss: 0.12523929727415303 , validation loss: 0.14070500066354327\n",
      "epoch 93 , train loss: 0.1253082361048309 , validation loss: 0.1407603311495189\n",
      "epoch 94 , train loss: 0.12532426541316863 , validation loss: 0.14067666096626408\n",
      "epoch 95 , train loss: 0.12528950785006407 , validation loss: 0.14068740451314155\n",
      "epoch 96 , train loss: 0.12529864751950975 , validation loss: 0.14064070220737562\n",
      "epoch 97 , train loss: 0.12523679538582363 , validation loss: 0.1407079010195758\n",
      "epoch 98 , train loss: 0.1252364419391095 , validation loss: 0.14066349925731655\n",
      "epoch 99 , train loss: 0.1253137240124752 , validation loss: 0.14066464346527618\n",
      "epoch 100 , train loss: 0.12521504656683227 , validation loss: 0.1406610936850962\n"
     ]
    }
   ],
   "source": [
    "min_val_loss = np.inf\n",
    "for epoch in range(1, epochs + 1):\n",
    "    l_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for x, y in train_iter:\n",
    "        y_pred = model(x).view(len(x), -1)\n",
    "        l = loss(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        l_sum += l.item() * y.shape[0]\n",
    "        n += y.shape[0]\n",
    "    scheduler.step()\n",
    "    val_loss = evaluate_model(model, loss, val_iter)\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    print(\"epoch\", epoch, \", train loss:\", l_sum / n, \", validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = STGCN(Ks, Kt, blocks, n_his, n_route, Lk, drop_prob).to(device)\n",
    "best_model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.13642582705203635 \n",
      "MAE: 2.2891189118890423 , MAPE: 0.05372799901972727 , RMSE: 4.017893806237947\n"
     ]
    }
   ],
   "source": [
    "l = evaluate_model(best_model, loss, test_iter)\n",
    "MAE, MAPE, RMSE = evaluate_metric(best_model, test_iter, scaler)\n",
    "print(\"test loss:\", l, \"\\nMAE:\", MAE, \", MAPE:\", MAPE, \", RMSE:\", RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
